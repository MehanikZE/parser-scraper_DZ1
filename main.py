import pickle
import re
import sys
from random import randint
from time import sleep as pause
from time import time

from bs4 import BeautifulSoup
from psycopg2 import connect
from selenium.webdriver import Chrome
from selenium.webdriver.chrome.service import Service

from tqdm import tqdm
from webdriver_manager.chrome import ChromeDriverManager

def to_postgresql_database(data) -> None:


    with connect(host='127.0.0.1', user='postgres',
                 password='Vrt342zf', database='parser') as connection:
        connection.autocommit = True

        with connection.cursor() as cursor:
            cursor.execute(
                f"DROP TABLE IF EXISTS nout;"
            )

            cursor.execute(
                f"""CREATE TABLE nout
                (id                    INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                url            INT,
                visited_at timestamp,
                name_c                  VARCHAR,
                cpu_hhz FLOAT,
                ram_gb INT                    ,
                ssd_gb INT,
                price_rub                  INT,
                rank       FLOAT);"""
            )

            for notebook in data:
                cursor.execute(
                    f"""INSERT INTO nout VALUES
                    (DEFAULT,
                    '{notebook['Ссылка']}',
                    '{notebook["Время посещения"]},
                    '{notebook["Модель"]},
                    '{notebook["Процессор"]},
                    '{notebook["Оперативка"]}',
                    '{notebook["SSD"]}',
                    '{notebook["Цена"]}',
                    '{notebook["Рейтингь"]}',
                    ')"""
                )


def get_all_notebook_urls(driver) -> list[str]:

    page = 1
    url_template = 'https://www.dns-shop.ru/catalog/17a892f816404e77/noutbuki/?p=1'

    url = url_template.format(page=page)
    driver.get(url=url)
    pause(10)

    urls = []
    while page_urls := get_urls_from_page(driver):
        print(f'Страница {page}')

        urls.extend(page_urls)

        url = url_template.format(page=page)

        page += 1

        driver.get(url)

        pause(randint(6, 9))
    return urls


def get_urls_from_page(driver) -> list[str]:

    soup = BeautifulSoup(driver.page_source, 'lxml')
    elements = soup.find_all('a', class_="catalog-product__name ui-link ui-link_black")
    return list(map(
        lambda element: 'https://www.dns-shop.ru' + element.get("href") + 'characteristics/',
        elements
    ))
#
#
def get_notebook_data(driver, url: str) -> dict[str, str | int]:

    notebook = dict()

    driver.get(url)
    pause(5)

    soup = BeautifulSoup(driver.page_source, 'lxml')

    model = find_if_on_page(r'Модель', soup)

    notebook["name_c"] = re.search(
        r"(Dream Machines|.+?) (.+)",
        model
    ).group(1, 2)

    cpu_frequency = find_if_on_page(r'Частота процессора', soup)
    notebook["cpu"] = f"{cpu_frequency} "
    amount_of_ram = find_if_on_page(r'Объем оперативной памяти', soup)
    notebook["RAM"] = f"{amount_of_ram} "
    total_ssd_size = find_if_on_page(r'(SSD\)',
                                     soup)
    notebook["SSD"] = f"{total_ssd_size}"

    notebook["SSD"] = find_if_on_page(
        r' (SDD)',
        soup
    ).capitalize()

    count = 0
    while True:
        soup = BeautifulSoup(driver.page_source, 'lxml')
        if old_price_element := soup.find('span', class_='product-buy__prev'):
            notebook["Цена"] = map(
                int, soup.find(
                    'div',
                    class_='product-buy__price product-buy__price_active'
                ).text.replace(' ', '').split('₽')
            )

        elif price := soup.find('div', class_='product-buy__price'):
            notebook["Цена"] = int(price.text.replace(' ', '')[:-1])
            break
        else:
            count += 1
            pause(1)
    notebook["Ссылка"] = url

    return notebook
#
#
def find_if_on_page(regex: str, soup) -> str:

    if (element := soup.find(
        text=re.compile(fr"^ ?{regex} ?$"),
    )) is not None:
        return element.find_next("div").text.strip()
    else:
        return "Нет"
#
#
def main():
    start_time = time()
    with Chrome(service=Service(ChromeDriverManager().install())) as driver:
        driver.maximize_window()

        print("Ссылки:")
        urls = get_all_notebook_urls(driver)
        with open('urls.txt', 'w') as file:
            file.write('\n'.join(urls))

        print("Параметры:")

        with open('urls.txt', 'r') as file:
            urls = list(map(lambda line: line.strip(), file.readlines()))

        notebooks = []
        for url in tqdm(urls, ncols=70, unit='notebook',
                        colour='green', file=sys.stdout):
            notebooks.append(get_notebook_data(driver, url))
# #
    with open('list.txt', 'wb+') as file:
        pickle.dump(notebooks, file)
#
    # with open('list.txt', 'rb') as file:
    #     notebooks = pickle.load(file)

    # config = dotenv_values(".env")
    # to_postgresql_database(
    #     notebooks, "Gaming notebooks",
    #     host=config['HOST'],
    #     user=config['USER_NAME'],
    #     password=config['PASSWORD'],
    #     database=config['DB_NAME']
    # )
#
    total_time = time() - start_time
    print(f"Время :\n"
          f"{(total_time // 3600):02.0f}:"
          f"{(total_time % 3600 // 60):02.0f}:"
          f"{(total_time % 60):02.0f}")


if __name__ == '__main__':
    main()
